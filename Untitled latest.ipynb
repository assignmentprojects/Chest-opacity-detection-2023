{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b443a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input,Dropout,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee1b8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory for working with the data\n",
    "\n",
    "if not os.path.exists('E:/python/deep_learning_project/dataset1/datasets'):\n",
    "    os.makedirs('E:/python/deep_learning_project/dataset1/datasets') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05c0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory for working with the data\n",
    "\n",
    "if not os.path.exists('E:/python/deep_learning_project/dataset1/datasets/training'):\n",
    "    os.makedirs('E:/python/deep_learning_project/dataset1/datasets/training') \n",
    "\n",
    "if not os.path.exists('E:/python/deep_learning_project/dataset1/datasets/testing'):\n",
    "    os.makedirs('E:/python/deep_learning_project/dataset1/datasets/testing') \n",
    "\n",
    "if not os.path.exists('E:/python/deep_learning_project/dataset1/datasets/validation'):\n",
    "    os.makedirs('E:/python/deep_learning_project/dataset1/datasets/validation') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d1f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"E:/python/deep_learning_project/dataset1/datasets/training/normal\"):\n",
    "    os.makedirs(\"E:/python/deep_learning_project/dataset1/datasets/training/normal\")\n",
    "if not os.path.exists(\"E:/python/deep_learning_project/dataset1/datasets/training/sick\"):\n",
    "    os.makedirs(\"E:/python/deep_learning_project/dataset1/datasets/training/sick\")\n",
    "if not os.path.exists(\"E:/python/deep_learning_project/dataset1/datasets/testing/normal\"):\n",
    "    os.makedirs(\"E:/python/deep_learning_project/dataset1/datasets/testing/normal\")\n",
    "if not os.path.exists(\"E:/python/deep_learning_project/dataset1/datasets/testing/sick\"):\n",
    "    os.makedirs(\"E:/python/deep_learning_project/dataset1/datasets/testing/sick\")\n",
    "if not os.path.exists(\"E:/python/deep_learning_project/dataset1/datasets/validation/normal\"):\n",
    "    os.makedirs(\"E:/python/deep_learning_project/dataset1/datasets/validation/normal\")\n",
    "if not os.path.exists(\"E:/python/deep_learning_project/dataset1/datasets/validation/sick\"):\n",
    "    os.makedirs(\"E:/python/deep_learning_project/dataset1/datasets/validation/sick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29748de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the dataset paths\n",
    "#train_path = 'E:/python/deep_learning_project/dataset1/datasets/train'\n",
    "#val_path = 'dataset1/known_images/val'\n",
    "#test_path = 'dataset1/known_images/test'\n",
    "#unknown_path = 'dataset1/unknown_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9944d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path  = 'E:/python/deep_learning_project/dataset1/known_images'\n",
    "images = os.listdir(main_path)\n",
    "\n",
    "normal_images = []\n",
    "sick_images = []\n",
    "\n",
    "# seperate normal images from sick images\n",
    "for image in images:\n",
    "    if image.startswith('normal'):\n",
    "        normal_images.append(image)\n",
    "    else:\n",
    "        sick_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71737fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train test and validation split for normal images\n",
    "def populate_normal_images(normal_images, path):\n",
    "    for i,img in enumerate(normal_images):\n",
    "        if i < 250:\n",
    "            shutil.copy(os.path.join(path, img),\n",
    "                      os.path.join(\"E:/python/deep_learning_project/dataset1/datasets/training/normal\", img))\n",
    "        elif i > 250 and i < (250+50):\n",
    "            shutil.copy(os.path.join(path, img),\n",
    "                      os.path.join(\"E:/python/deep_learning_project/dataset1/datasets/testing/normal\", img))\n",
    "        else:\n",
    "              if i > 364:\n",
    "                return\n",
    "              shutil.copy(os.path.join(path, img),\n",
    "                          os.path.join(\"E:/python/deep_learning_project/dataset1/datasets/validation/normal\", img))\n",
    "    return\n",
    "    \n",
    "populate_normal_images(normal_images,main_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d431c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train test and validation split for  sick images\n",
    "def populate_sick_images(sick_images,path):\n",
    "    for i,img in enumerate(sick_images):\n",
    "        if i < 250:\n",
    "            shutil.copy(os.path.join(path, img),\n",
    "                      os.path.join(\"E:/python/deep_learning_project/dataset1/datasets/training/sick\", img))\n",
    "        elif i > 250 and i < (250+50):\n",
    "            shutil.copy(os.path.join(path, img),\n",
    "                      os.path.join(\"E:/python/deep_learning_project/dataset1/datasets/testing/sick\", img))\n",
    "        else:\n",
    "              if i > (351):\n",
    "                return\n",
    "              shutil.copy(os.path.join(path, img),\n",
    "                          os.path.join(\"E:/python/deep_learning_project/dataset1/datasets/validation/sick\", img))\n",
    "    return\n",
    "\n",
    "populate_sick_images(sick_images,main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0538896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "#IMAGE_SIZE = 224\n",
    "#BATCH_SIZE = 32\n",
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e962f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91901217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, val, test\n",
    "#train_images = known_images[:int(len(known_images)*TRAIN_SIZE)]\n",
    "#val_images = known_images[int(len(known_images)*TRAIN_SIZE):int(len(known_images)*(TRAIN_SIZE+VAL_SIZE))]\n",
    "#test_images = known_images[int(len(known_images)*(TRAIN_SIZE+VAL_SIZE)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aaa28c",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "355e6b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and batch size\n",
    "img_size = (224, 224)\n",
    "#batch_size = 16\n",
    "#EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "275ddf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation parameters for the training set\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af155cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the training set\n",
    "train_set = train_datagen.flow_from_directory('E:/python/deep_learning_project/dataset1/datasets/training',\n",
    "                                              target_size=(224, 224),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9bcf299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the test set\n",
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory('E:/python/deep_learning_project/dataset1/datasets/testing',\n",
    "                                                                   #target_size=img_size,\n",
    "                                                                   target_size=(224, 224),\n",
    "                                                                   batch_size=32,\n",
    "                                                                   class_mode='binary',\n",
    "                                                                   shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56cd7d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 117 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the validation set\n",
    "val_set = ImageDataGenerator(rescale=1./255).flow_from_directory('E:/python/deep_learning_project/dataset1/datasets/validation',\n",
    "                                                                  target_size=(224, 224),\n",
    "                                                                  batch_size=32,\n",
    "                                                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7186545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "Dropout(0.5),\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fca9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e4f3600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "16/16 [==============================] - 71s 4s/step - loss: 0.7058 - accuracy: 0.6280 - val_loss: 0.5769 - val_accuracy: 0.6410\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 67s 4s/step - loss: 0.4966 - accuracy: 0.7740 - val_loss: 0.5130 - val_accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "# Train the model and setting callbacks for our model\n",
    "early_stopping_monitor = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "reduce_lr_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    ")\n",
    "\n",
    "best_model = ModelCheckpoint('bestmodel.hdf5', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "history = model.fit(train_set,\n",
    "           epochs= 2,\n",
    "           batch_size=32,\n",
    "           validation_data=val_set,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1261ec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 851ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "prediction = model.predict(test_set)\n",
    "y_pred = (prediction > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a082f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82559e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 830ms/step - loss: 0.6137 - accuracy: 0.6939\n",
      "4/4 [==============================] - 4s 802ms/step - loss: 0.6137 - accuracy: 0.6939\n",
      "4/4 [==============================] - 4s 808ms/step - loss: 0.6137 - accuracy: 0.6939\n",
      "4/4 [==============================] - 4s 808ms/step - loss: 0.6137 - accuracy: 0.6939\n",
      "Accuracy        : 0.6938775777816772\n",
      "Precision       : 0.6938775777816772\n",
      "Recall          : 0.6938775777816772\n",
      "F1-score        : 0.6938775777816772\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, accuracy = model.evaluate(test_set)\n",
    "test_loss, precision = model.evaluate(test_set)\n",
    "test_loss, recall = model.evaluate(test_set)\n",
    "test_loss, f1score = model.evaluate(test_set)\n",
    "print('Accuracy        :',(accuracy))\n",
    "print('Precision       :',(precision))\n",
    "print('Recall          :',(recall))\n",
    "print('F1-score        :',(f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38e5c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "922e3fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77        79\n",
      "           1       0.39      1.00      0.56        19\n",
      "\n",
      "    accuracy                           0.69        98\n",
      "   macro avg       0.69      0.81      0.66        98\n",
      "weighted avg       0.88      0.69      0.73        98\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_classification_report(pred, test_set):\n",
    "    # Generate status classification report\n",
    "    print(classification_report(pred, test_set.classes))\n",
    "\n",
    "    # confusion matrix\n",
    "    cm_status = confusion_matrix(test_set.classes, pred)\n",
    "\n",
    "    # Plot status confusion matrix as heatmap\n",
    "    sns.heatmap(cm_status, annot=True)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show\n",
    "\n",
    "generate_classification_report(y_pred, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96506ad9",
   "metadata": {},
   "source": [
    "## Predicting the unknown images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6da7849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 683ms/step\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Define paths to data and load into a list\n",
    "unknown_images_path = 'E:/python/deep_learning_project/dataset1/unknown_images'\n",
    "images = os.listdir(unknown_images_path)\n",
    "unknown_images = []\n",
    "for img_sets in images:\n",
    "    unknown_image_path = f'{unknown_images_path}/{img_sets}'\n",
    "    unknown_image = tf.keras.preprocessing.image.load_img(unknown_image_path, target_size=(224, 224))\n",
    "    unknown_image = tf.keras.preprocessing.image.img_to_array(unknown_image)\n",
    "    unknown_image = np.expand_dims(unknown_image, axis=0)\n",
    "    unknown_images.append(unknown_image)\n",
    "\n",
    "# Concatenate the unknown images into an array\n",
    "unknown_images = np.concatenate(unknown_images, axis=0)\n",
    "\n",
    "# Make predictions on the unknown images\n",
    "predictions = model.predict(unknown_images)\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "results = []\n",
    "result_labels = []\n",
    "\n",
    "# Print the predictions\n",
    "for i, prediction in enumerate(predictions):\n",
    "    result_labels.append(f'Image {i+1}')\n",
    "    results.append(prediction[0])\n",
    "    \n",
    "classes = np.argmax(predictions, axis = 1)\n",
    "print(classes)\n",
    "\n",
    "#create results dataframe\n",
    "results_df = pd.DataFrame({'Image': result_labels, 'Prediction': results})\n",
    "\n",
    "# save the dataframe to a CSV file\n",
    "results_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "602345f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_sets):\n",
    "    # Load an image\n",
    "    img = cv2.imread(img_sets)\n",
    "    img_filtered = cv2.GaussianBlur(img_sets, (3, 3), 0.5)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c65d9db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 9s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset2 into a list\n",
    "dataset2_path = 'E:\\python\\deep_learning_project\\dataset2\\images'\n",
    "images = os.listdir(dataset2_path)\n",
    "class_images = []\n",
    "for img_sets in images:\n",
    "    dataset2_image_path = f'{dataset2_path}/{img_sets}'\n",
    "    all_dataset2_images = tf.keras.preprocessing.image.load_img(dataset2_image_path, target_size=(224, 224))\n",
    "    all_dataset2_images = tf.keras.preprocessing.image.img_to_array(all_dataset2_images)\n",
    "    all_dataset2_images = np.expand_dims(all_dataset2_images, axis=0)\n",
    "    class_images.append(all_dataset2_images)\n",
    "\n",
    "# Concatenate the unknown images into an array\n",
    "class_images = np.concatenate(class_images, axis=0)\n",
    "\n",
    "# Make predictions on the dataset2 images\n",
    "dataset2_pred = model.predict(class_images)\n",
    "dataset2_pred = (dataset2_pred > 0.5).astype(int)\n",
    "y_pred = []\n",
    "\n",
    "# Print the predictions\n",
    "for i, prediction in enumerate(dataset2_pred):\n",
    "    y_pred.append(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "385b817d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:/python/deep_learning_project/dataset2/image_classes.csv')\n",
    "y_test=df.iloc[:, 1]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preditions on dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aab07fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset2_images(path):\n",
    "  imagePaths = list(paths.list_images(path))\n",
    "  unknown_data = []\n",
    "  \n",
    "  # loop over the image paths\n",
    "  for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # Gaussian blur for smothening and removing noise in the image\n",
    "    image = cv2.Sobel(src=image, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5)\n",
    "    \n",
    "    # update the data and labels lists, respectively\n",
    "    unknown_data.append(image)\n",
    "  unknown_data = np.array(unknown_data) / 255.0\n",
    "\n",
    "  return unknown_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "72038e99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data and make preditions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset2 \u001b[38;5;241m=\u001b[39m \u001b[43mdataset2_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset2_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m dataset2_predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dataset2)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Generate arg maxes for predictions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[109], line 2\u001b[0m, in \u001b[0;36mdataset2_images\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdataset2_images\u001b[39m(path):\n\u001b[1;32m----> 2\u001b[0m   imagePaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mpaths\u001b[49m\u001b[38;5;241m.\u001b[39mlist_images(path))\n\u001b[0;32m      3\u001b[0m   unknown_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;66;03m# loop over the image paths\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the data and make preditions\n",
    "dataset2 = dataset2_images(dataset2_path)\n",
    "dataset2_predict = model.predict(dataset2)\n",
    "\n",
    "# Generate arg maxes for predictions\n",
    "dataset2_classes = np.argmax(dataset2_predict, axis = 1)\n",
    "print(dataset2_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
